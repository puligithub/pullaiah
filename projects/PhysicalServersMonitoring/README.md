# Physical Servers Monitoring

**Title:** Physical Servers (DELL, HP & LENOVO) Monitoring  
**Objective:** Endâ€‘toâ€‘end, agentless monitoring of physical servers with a centralized Splunk dashboard and automated ServiceNow incident creation.  
**Business Impact:** Reduced Mean Time to Repair (MTTR) by **80%**, enabling proactive hardware fault remediation and improved customer satisfaction.

---

**> IBM ESA Container runs in GKE, collects hardware metrics via SNMP.

> Splunk Dashboard visualizes health and triggers alerts.

> Python Script ingests alerts and autoâ€‘creates ServiceNow incidents.

> Multiâ€‘Zone GKE for high availability and regionâ€‘spanning coverage.**

---
 **Tools & Technologies** 

> IBM ESA (beta container image)

> Google Kubernetes Engine (GKE) â€“ multiâ€‘zone clusters

> SNMP â€“ agentless polling across platforms

> Splunk Infrastructure Monitoring â€“ centralized dashboard & alerting

> ServiceNow API â€“ incident creation via Python scripts

> Jenkins â€“ CI/CD for image scanning & deployment

> SRE Practices â€“ SLO tracking, MTTR metrics, retrospectives

---
  
## ğŸ“‹ Agile Process

We followed a **Scrumâ€‘style Agile** approach over a **12â€‘month** engagement, delivering in twoâ€‘week sprints:

1. **Sprint Planning & Backlog Grooming**  
   - Refined user stories for SNMP integration, dashboarding, and incident workflows.  
2. **Daily Standâ€‘ups**  
   - Coordinated Unix, Windows, and VMware platform teams; addressed blockers in real time.  
3. **Sprint Reviews & Demos**  
   - Showcased incremental capabilities to stakeholders; collected feedback for the next iteration.  
4. **Retrospectives**  
   - Improved CI/CD pipelines, vendor collaboration, and alertâ€‘tuning processes.

---

## ğŸ—“ï¸ Project Timeline

| Sprint  | Dates    | Key Deliverables                              |
|:-------:|----------|-----------------------------------------------|
| 1â€“2     |NA      | GKE cluster provisioning; IBM ESA beta deploy |
| 3â€“6     | JNA    | SNMP polling; Splunk dashboard MVP            |
| 7â€“10    | NA     | ServiceNow API scripts; incident routing      |
| 11â€“12   | NA     | Multiâ€‘region rollout; performance hardening   |

> _Each sprint spanned two weeks, enabling rapid feedback and continuous improvement._

---

## ğŸ› ï¸ Tools & Technologies

We list only the core tools to keep the README concise and recruiterâ€‘friendlyâ€”per recommended â€œPrerequisitesâ€ and â€œToolsâ€ sections :contentReference[oaicite:1]{index=1}:  
- **IBM ESA** (beta container image)  
- **Google Kubernetes Engine (GKE)** â€“ multiâ€‘zone clusters  
- **SNMP** â€“ agentless polling across platforms  
- **Splunk Infrastructure Monitoring** â€“ centralized dashboard & alerting  
- **ServiceNow API** â€“ incident creation via Python scripts  
- **Jenkins** â€“ CI/CD pipelines for image scanning & deployment  
- **Languages & Scripting:** Python, Shell, YAML  
- **SRE Practices:** SLO tracking, MTTR metrics, retrospectives :contentReference[oaicite:2]{index=2}

---

## ğŸ“ File Structure

A clear, topâ€‘level layout guides contributorsâ€”mirroring industry conventions :contentReference[oaicite:3]{index=3}:

â”œâ”€â”€ README.md â† Project overview (this file) â”œâ”€â”€ docs/ â† Architecture & Agile process details â”‚ â”œâ”€â”€ architecture.md â”‚ â””â”€â”€ agile_process.md â”œâ”€â”€ k8s/ â† Kubernetes manifests & configs â”‚ â””â”€â”€ deployment.yaml â”œâ”€â”€ scripts/ â† Automation & incident logic â”‚ â””â”€â”€ create_incident.py â””â”€â”€ LICENSE â†

---

## ğŸ”¥ Highlights & Importance

> **IMPORTANT**  
> - **MTTR â†“Â 80%:** Automated alerting & incident creation cut hardware repair times from 10Â hrs to <Â 2Â hrs.  
> - **Agentless SNMP:** Supported Dell, HP, and Lenovo servers without installing host agents.  
> - **Multiâ€‘Region HA:** GKE multiâ€‘zone clusters ensure failover and resilience.  
> - **Vendor Collaboration:** Partnered with IBM ESA beta team for product hardening and feature stabilization.

---

## âš™ï¸ Implementation

This section describes **how we built** the systemâ€”following â€œwrite your README before your codeâ€ to clarify scope :contentReference[oaicite:4]{index=4}:  
1. **Provision GKE cluster** with multiâ€‘zone nodes and network policies.  
2. **Deploy IBM ESA** container via Helm chart; configure SNMP targets for Dell, HP, Lenovo servers.  
3. **Integrate with Splunk** using HTTP Event Collector for realâ€‘time dashboards and alerts.  
4. **Automate ServiceNow incidents** by triggering Python scripts on Splunk alerts, ensuring correct assignment & logging.  
5. **Harden container images** in CI/CD (Jenkins) with vulnerability scanning and automated rollbacks.  
6. **Extend crossâ€‘region** coverage by replicating Helm releases and maintaining a unified config repository. :contentReference[oaicite:5]{index=5}

---

## ğŸš€ Usage

Quickstart commandsâ€”modeled after â€œGetting Startedâ€ examplesâ€”to get you up and running in minutes :contentReference[oaicite:6]{index=6}:

```bash
# 1. Deploy IBM ESA on GKE
kubectl apply -f k8s/deployment.yaml

# 2. Configure Splunk HEC
#    - Set `SPLUNK_HEC_TOKEN` & `SPLUNK_HEC_URL` in ESA config

# 3. Run incident creation script
python3 scripts/create_incident.py --alert-id <ALERT_ID>

# 4. View dashboards
#    - Login to Splunk â†’ Dashboards â†’ â€œPhysical Servers Healthâ€
```
---

## ğŸ—ï¸ Architecture & Design

```mermaid
flowchart LR
  subgraph "GKE Cluster"
    ESA["IBM ESA Container"]
    SNMP["SNMP Polling"]
    ESAdash["Splunk Dashboard"]
    ESASNOW["ServiceNow API Script"]
    ESA -->|SNMP Polling| SNMP
    ESA --> ESAdash
    ESA --> ESASNOW
  end

  subgraph "Physical Servers"
    DELL["DELL Server"]
    HP["HP Server"]
    LENOVO["LENOVO Server"]
  end

  DELL <--->|SSH, SNMP, Logs via HTTPS| ESA
  HP   <--->|SSH, SNMP, Logs via HTTPS| ESA
  LENOVO <--->|SSH, SNMP, logs via HTTPS| ESA

  subgraph "Onâ€‘Estate Proxy"
    InternalProxy["Internal Proxy Server"]
  end

  ESA -->|Incident events Forwarding| ESAdash
  ESA -->| Logs | InternalProxy
  ESASNOW <-->|API Calls| ESA
  SNMP -->|HW events & Alerts Forwarding| InternalProxy

  subgraph "IBM Proxy & Portal"

    IBMProxy["IBM Proxy"]
    IBMPortal["IBM Vendor Portal"]
    IBMProxy --> IBMPortal
  end

  InternalProxy -->|HTTPS| IBMProxy
